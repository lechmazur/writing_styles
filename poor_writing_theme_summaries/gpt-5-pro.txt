Across the high‑severity set, gpt-5-pro’s weakest writing is not a single “purple prose” habit but a recurring control failure: when it tries to maximize impact per sentence, it stops enforcing the story’s literal constraints. The model reliably “turns up” lyricism at openings, climaxes, and closings, and in those moments the image-maker outcompetes the simulator. That’s how you get lines that are striking in isolation but physically or conceptually impossible, like “the standing waves decayed like candle smoke returning to wax.” The same impulse produces strange object metaphors that collapse visualization—“sealed with wax that crumbled under the muscles of the hum.”—and mixed frames that fight each other in a single beat, as in “two lovers sharing a lantern of soup.” The reader’s problem isn’t that the prose is ornate; it’s that the sentence no longer maps to a pictureable event, so the narrative camera goes out of focus precisely when it’s supposed to sharpen.

The second consistent failure is tracking who is doing what inside those dense, ornamented sentences. gpt-5-pro tends to preserve cadence through long clauses, parallel structures, and colon add-ons, but under that syntactic load it loses attachment and antecedents. That yields dangling modifiers (“Mara arrived at the disused railway station… carrying…”) and pronouns that could refer to multiple nouns (“It asked for mercy…”). In reveal scenes, the same pronoun set gets reused for different entities, so action ownership blurs: “Their hands hovered…” followed by “When they lifted it off…” and then the reveal “The intruder was Mira…” forces the reader to stop and reconstruct who “they” was at each step. Even when the intended meaning is plausible, the local next-token drive favors continuing the rhythmic structure over resolving reference, so the prose keeps moving while the reader gets left behind.

Those same attention-and-constraint limits show up as concrete bookkeeping errors: object state, spatial setup, and time anchors revert after transitions. The extreme examples are outright contradictions—“Before they left, I gave them…” versus later “opened three jars… and the keeper’s melody…”, or the door that exists and doesn’t (“At the door hung a cold doorknocker ring…” next to “if I had not removed it years ago.”). You see it again in prop teleports (“The tide would decide if it stayed…” then “Back at the room… The painting from the cave…”) and in time labels that reset to an earlier moment (“In the shadowed library at dawn…” followed by “He left… at dawn…” after the scene has progressed). Mechanistically, this looks like generation that is locally coherent but not globally constrained: once the model leaves a beat, it doesn’t reliably consult a persistent state representation, so it reintroduces “the” object or “at dawn” as if it were still in the initial setup.

Payoffs then suffer because the same style-over-substance bias replaces causal bridges with thematic closure. Instead of showing the mechanism, cost, or fallout, gpt-5-pro often asserts a satisfying outcome and moves on. That’s the engine behind “Outside, the war stood and turned home.” and the corridor hand‑wave—“I did not ask what price the corridor had demanded…”—which actively instructs the reader not to look for a causal chain. In climaxes, this can turn a hard problem into deus ex intuition: one harsh harmonic somehow makes someone pick the correct exit “without knowing why,” which reads less like mysterious logic and more like missing connective tissue. The model’s planner seems to optimize for emotional resolution (“mercy,” “home,” “freedom”) under wordcount pressure, and the connective steps are the first thing it drops.

Finally, register and “precision” drift reinforce all of the above by making the text sound authoritative even when the underlying model is underspecified. gpt-5-pro will splice clinical or technical prestige terms into lyrical narration—“My craft is not magic; it is biology… synaptic plasticity…”—or puncture the voice with meta/process debris like “Tone: None for the first telling.” When it reaches for modern-domain jargon (“procedural generation”), it can accidentally reframe the whole ontology of the story mid-paragraph. This matters because readers use voice as a reliability signal: when the prose claims analytic exactness (“factually mystical”) or drops a production note, it highlights that the story is being assembled from templates rather than simulated. In practice, the failure triggers cluster: intensify lyricism, compress explanation, or transition scenes quickly, and you simultaneously get metaphor collisions, reference ambiguity, continuity slips, and payoff hand‑waving—different surface errors driven by the same underlying loss of constraint enforcement as the model chases maximal evocative novelty per sentence.