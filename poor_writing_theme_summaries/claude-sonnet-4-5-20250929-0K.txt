Claude-sonnet-4.5’s worst writing failures aren’t random glitches so much as a consistent collapse of global constraints under narrative “pressure.” When the story needs to feel lyrical, profound, or climactic, the model aggressively optimizes for local intensity and cadence, and it does so without reliably persisting a single, shared world state across paragraphs. That’s why you see premises announced as absolutes and then treated as optional texture. If “time had become a strange loop, always today,” the text still describes “a moon three-quarters full, waxing toward completion,” because the immediate sentence-level goal (evoking eerie beauty) overrides the earlier rule (no advancing day). The same mechanism shows up in miniature with basic actions: “She sealed her report… then deliberately left it unsealed.” The output reads like a draft because the decoder is selecting high-salience phrases that fit the moment’s tone, not verifying that the combined proposition can be true at once.

The largest single driver of “poor writing” here is mechanics drift: the model can produce convincing-sounding scientific or magical rhetoric, but it doesn’t maintain a stable causal spine. It pattern-matches the sound of explanation (“orbital decay,” “time dilation,” “observation collapse”) while letting meanings invert or mutate. The canonical example is “It’s the orbital decay… The moon is leaving us,” which is a confidence-shaped sentence that reverses what the term implies; later it doubles down with “already infinitesimally farther.” Likewise, it can assert an extreme rule—“friction had vanished from the world”—then write ordinary choreography like “Korin knelt, arranging painted rocks” as if nothing changed, because the planner isn’t running implication checks (what becomes impossible?) and the prose engine continues to emit familiar human actions. The trigger boundary is clear: once the story enters “explain the conceit” mode or tries to justify wonder with technical language, the model starts improvising mechanism-sounding statements paragraph by paragraph, and each paragraph can overwrite the last.

A related failure is timeline snapping and event-ledger loss: numbers, durations, and “what time is it” anchors are treated as rhythmic devices rather than bookkeeping commitments. You get lines like “He stood on the midnight ridgeway at twilight” or structures that can’t be reconciled: “Her method seemed impossible, yet week by week…” followed immediately by “On the third day…,” then reiterated as “three days before the collapse.” In other cases the math simply doesn’t add up, as with “seventeen others” → “eighteen gears” → “the nineteenth piece,” or long labor compressed into a night: “When dawn broke…” then “They’d spent weeks…” This isn’t merely inattentiveness; it’s a planning-horizon limitation where the model keeps only a shallow working set of constraints, and it also has a strong symmetry bias—repeating “three days before…” or stepping 17/18/19—so the pattern’s elegance wins even when the implied timeline becomes impossible.

When the model can’t bridge causality cleanly, it often resorts to scene stitching shortcuts and deus-ex cognition: it jumps to the desired next state without simulating the intermediate struggle or inference. That’s how an armed confrontation becomes “Galloway… holding a lantern and a pistol” and then, without any depicted reversal, “Galloway bound and following.” It’s also how mysteries and technical problems get solved by miracle-tools or intuition masquerading as insight: “The ephemeral patterns in spilled ink became a map, a key,” or “Understanding flooded through her,” or “She knew without knowing.” Mechanistically, this is the same local-optimization problem: the model is trying to satisfy a payoff constraint (resolve the scene, deliver the reveal) while skipping the costful token budget of negotiation, failed attempts, and concrete clue chaining. Under climax pressure, it treats opposition as decorative setup—an “approaching boat” can be introduced and then abandoned—because internal realization is cheaper than simulating an adversary who keeps acting.

Finally, its “elevated” style prior is not just a taste issue; it actively increases semantic error rate. The model stacks intensifiers and motif phrases that sound lyrical but don’t compose into a coherent image, then repeats them as if repetition will stabilize meaning: “a vibrant hush,” “quietly explosive,” “brightening darkness.” It also drifts into thesis voice to force coherence when the underlying causal model is unstable, producing lines that label rather than dramatize, like “emotionally rational,” or rhetorical explanations that read like an op-ed inside fiction. At the token level, the same pressure yields corruption: wrong names (“Background said”), tense jolts (“was… she explains”), malformed adverbs (“Balancedly”), and stray glyphs (“absence of human声音,” “by the密度”). These aren’t separate problems; they’re coupled. The more the model leans on ornament, jargon-poetry, and abstraction to sound “important,” the less bandwidth remains for constraint checking, entity tracking, and concrete causal linkage—so the prose becomes simultaneously grander and less reliable, especially at precisely the moments (revelations, awe beats, confrontations) where readers demand the tightest continuity.